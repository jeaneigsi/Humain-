{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyfL8ZSF2vKlxV36ddqM9i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeaneigsi/Humain-/blob/main/instruct_deberta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/kevinscaria/InstructABSA/tree/main   \n",
        "https://huggingface.co/yangheng/deberta-v3-large-absa-v1.1   \n",
        "wget https://github.com/kevinscaria/InstructABSA/blob/main/instructions.py"
      ],
      "metadata": {
        "id": "VXiFxbSDSFiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification,pipeline\n",
        "\n",
        "# Load the ABSA model and tokenizer\n",
        "model_name = \"yangheng/deberta-v3-large-absa-v1.1\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "for aspect in word_list :\n",
        "   print(aspect, classifier('the screen is bad and phone also but design is amazing',  text_pair=aspect))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiDI7sjtvudC",
        "outputId": "16ac1a88-209e-41a8-ac77-8abb830f5bb1"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "camera [{'label': 'Negative', 'score': 0.997731626033783}]\n",
            "quality, [{'label': 'Negative', 'score': 0.9094060659408569}]\n",
            "battery [{'label': 'Negative', 'score': 0.5619088411331177}]\n",
            "life, [{'label': 'Positive', 'score': 0.9305965900421143}]\n",
            "screen [{'label': 'Negative', 'score': 0.9998279809951782}]\n",
            "brightness, [{'label': 'Negative', 'score': 0.7214969396591187}]\n",
            "design, [{'label': 'Positive', 'score': 0.9998764991760254}]\n",
            "weight, [{'label': 'Positive', 'score': 0.9953311085700989}]\n",
            "phone [{'label': 'Negative', 'score': 0.9997301697731018}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRLoQYxvRCe-",
        "outputId": "7245d2dc-2bbd-47c1-f33b-745c3af0d86b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['camera',\n",
              " 'quality,',\n",
              " 'battery',\n",
              " 'life,',\n",
              " 'screen',\n",
              " 'brightness,',\n",
              " 'design,',\n",
              " 'weight,',\n",
              " 'phone']"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "warnings.warn(\n",
        "camera [{'label': 'Positive', 'score': 0.9967294931411743}]\n",
        "phone [{'label': 'Neutral', 'score': 0.9472787380218506}]"
      ],
      "metadata": {
        "id": "x9AtEy6j3DYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Load the ABSA model and tokenizer\n",
        "model_name = \"yangheng/deberta-v3-large-absa-v1.1\"\n",
        "tokenizers = AutoTokenizer.from_pretrained(model_name)\n",
        "models = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "# Function to run ABSA inference manually\n",
        "def classify_text(model, tokenizer, text, aspect):\n",
        "    # Prepare input as a pair of sentences (main text and aspect)\n",
        "    inputs = tokenizers(text, aspect, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    # Forward pass through the model to get logits\n",
        "    with torch.no_grad():\n",
        "        outputs = models(**inputs)\n",
        "\n",
        "    # Apply softmax to get probabilities\n",
        "    probabilities = torch.softmax(outputs.logits, dim=-1)\n",
        "\n",
        "    # Get the predicted class (argmax of the logits)\n",
        "    predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
        "\n",
        "    # Map predicted class to sentiment labels (assumed 0=negative, 1=neutral, 2=positive)\n",
        "    sentiment_labels = ['negative', 'neutral', 'positive']\n",
        "    predicted_sentiment = sentiment_labels[predicted_class]\n",
        "\n",
        "    return predicted_sentiment, probabilities\n",
        "\n",
        "# Example text and aspects\n",
        "text = \"The camera quality of this phone is amazing.\"\n",
        "aspects = ['camera', 'phone']\n",
        "\n",
        "# Loop over aspects and classify\n",
        "for aspect in aspects:\n",
        "    sentiment, probabilities = classify_text(model, tokenizer, text, aspect)\n",
        "\n",
        "    # Output similar to pipeline\n",
        "    print(f\"Aspect: {aspect}, Sentiment: {sentiment}, Probabilities: {torch.argmax(probabilities, dim=-1)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPlrPScD2rju",
        "outputId": "fc958a51-a979-4abb-cf3b-54ec3e5c7003"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aspect: camera, Sentiment: positive, Probabilities: tensor([2])\n",
            "Aspect: phone, Sentiment: neutral, Probabilities: tensor([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input=\"The food was delicious\"\n",
        "aspect=\"Service\"\n",
        "inputs = tokenizers(input, aspect, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "with torch.no_grad():\n",
        "    outputs = models(**inputs)\n",
        "    pred=torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "sentiment=['negative','neutral','positive']\n",
        "print(f\"Sentiment : {sentiment[pred.item()]} and {torch.softmax(outputs.logits, dim=-1)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsWko8p25cFM",
        "outputId": "5da5a668-14cc-44af-e24e-bc6c7fcd56ff"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment : neutral and tensor([[4.9511e-04, 9.8943e-01, 1.0076e-02]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instructabsa"
      ],
      "metadata": {
        "id": "PWh3WfXVI7dF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from tqdm import tqdm\n",
        "from transformers import (\n",
        "    DataCollatorForSeq2Seq, AutoTokenizer, AutoModelForSeq2SeqLM,\n",
        "    Seq2SeqTrainingArguments, Trainer, Seq2SeqTrainer\n",
        ")\n",
        "\n",
        "\n",
        "class T5Generator:\n",
        "    def __init__(self, model_checkpoint):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
        "        self.data_collator = DataCollatorForSeq2Seq(self.tokenizer)\n",
        "        self.device = 'cuda' if torch.has_cuda else ('mps' if torch.has_mps else 'cpu')\n",
        "\n",
        "    def tokenize_function_inputs(self, sample):\n",
        "        \"\"\"\n",
        "        Udf to tokenize the input dataset.\n",
        "        \"\"\"\n",
        "        model_inputs = self.tokenizer(sample['text'], max_length=512, truncation=True)\n",
        "        labels = self.tokenizer(sample[\"labels\"], max_length=64, truncation=True)\n",
        "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "        return model_inputs\n",
        "\n",
        "    def train(self, tokenized_datasets, **kwargs):\n",
        "        \"\"\"\n",
        "        Train the generative model.\n",
        "        \"\"\"\n",
        "        #Set training arguments\n",
        "        args = Seq2SeqTrainingArguments(\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "        # Define trainer object\n",
        "        trainer = Seq2SeqTrainer(\n",
        "            self.model,\n",
        "            args,\n",
        "            train_dataset=tokenized_datasets[\"train\"],\n",
        "            eval_dataset=tokenized_datasets[\"validation\"] if tokenized_datasets.get(\"validation\") is not None else None,\n",
        "            tokenizer=self.tokenizer,\n",
        "            data_collator=self.data_collator,\n",
        "        )\n",
        "        print(\"Trainer device:\", trainer.args.device)\n",
        "\n",
        "        # Finetune the model\n",
        "        torch.cuda.empty_cache()\n",
        "        print('\\nModel training started ....')\n",
        "        trainer.train()\n",
        "\n",
        "        # Save best model\n",
        "        trainer.save_model()\n",
        "        return trainer\n",
        "\n",
        "    def get_labels(self, tokenized_dataset, batch_size = 4, max_length = 128, sample_set = 'train'):\n",
        "        \"\"\"\n",
        "        Get the predictions from the trained model.\n",
        "        \"\"\"\n",
        "        def collate_fn(batch):\n",
        "            input_ids = [torch.tensor(example['input_ids']) for example in batch]\n",
        "            input_ids = pad_sequence(input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
        "            return input_ids\n",
        "\n",
        "        dataloader = DataLoader(tokenized_dataset[sample_set], batch_size=batch_size, collate_fn=collate_fn)\n",
        "        predicted_output = []\n",
        "        self.model.to(self.device)\n",
        "        print('Model loaded to: ', self.device)\n",
        "\n",
        "        for batch in tqdm(dataloader):\n",
        "            batch = batch.to(self.device)\n",
        "            output_ids = self.model.generate(batch, max_length = max_length)\n",
        "            output_texts = self.tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
        "            for output_text in output_texts:\n",
        "                predicted_output.append(output_text)\n",
        "        return predicted_output\n",
        "\n",
        "    def get_metrics(self, y_true, y_pred, is_triplet_extraction=False):\n",
        "        total_pred = 0\n",
        "        total_gt = 0\n",
        "        tp = 0\n",
        "        if not is_triplet_extraction:\n",
        "            for gt, pred in zip(y_true, y_pred):\n",
        "                gt_list = gt.split(', ')\n",
        "                pred_list = pred.split(', ')\n",
        "                total_pred+=len(pred_list)\n",
        "                total_gt+=len(gt_list)\n",
        "                for gt_val in gt_list:\n",
        "                    for pred_val in pred_list:\n",
        "                        if pred_val in gt_val or gt_val in pred_val:\n",
        "                            tp+=1\n",
        "                            break\n",
        "\n",
        "        else:\n",
        "            for gt, pred in zip(y_true, y_pred):\n",
        "                gt_list = gt.split(', ')\n",
        "                pred_list = pred.split(', ')\n",
        "                total_pred+=len(pred_list)\n",
        "                total_gt+=len(gt_list)\n",
        "                for gt_val in gt_list:\n",
        "                    gt_asp = gt_val.split(':')[0]\n",
        "\n",
        "                    try:\n",
        "                        gt_op = gt_val.split(':')[1]\n",
        "                    except:\n",
        "                        continue\n",
        "\n",
        "                    try:\n",
        "                        gt_sent = gt_val.split(':')[2]\n",
        "                    except:\n",
        "                        continue\n",
        "\n",
        "                    for pred_val in pred_list:\n",
        "                        pr_asp = pred_val.split(':')[0]\n",
        "\n",
        "                        try:\n",
        "                            pr_op = pred_val.split(':')[1]\n",
        "                        except:\n",
        "                            continue\n",
        "\n",
        "                        try:\n",
        "                            pr_sent = gt_val.split(':')[2]\n",
        "                        except:\n",
        "                            continue\n",
        "\n",
        "                        if pr_asp in gt_asp and pr_op in gt_op and gt_sent == pr_sent:\n",
        "                            tp+=1\n",
        "\n",
        "        p = tp/total_pred\n",
        "        r = tp/total_gt\n",
        "        return p, r, 2*p*r/(p+r), None\n",
        "\n",
        "\n",
        "class T5Classifier:\n",
        "    def __init__(self, model_checkpoint):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, force_download = True)\n",
        "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint, force_download = True)\n",
        "        self.data_collator = DataCollatorForSeq2Seq(self.tokenizer)\n",
        "        self.device = 'cuda' if torch.has_cuda else ('mps' if torch.has_mps else 'cpu')\n",
        "\n",
        "    def tokenize_function_inputs(self, sample):\n",
        "        \"\"\"\n",
        "        Udf to tokenize the input dataset.\n",
        "        \"\"\"\n",
        "        sample['input_ids'] = self.tokenizer(sample[\"text\"], max_length = 512, truncation = True).input_ids\n",
        "        sample['labels'] = self.tokenizer(sample[\"labels\"], max_length = 64, truncation = True).input_ids\n",
        "        return sample\n",
        "\n",
        "    def train(self, tokenized_datasets, **kwargs):\n",
        "        \"\"\"\n",
        "        Train the generative model.\n",
        "        \"\"\"\n",
        "\n",
        "        # Set training arguments\n",
        "        args = Seq2SeqTrainingArguments(\n",
        "            **kwargs\n",
        "            )\n",
        "\n",
        "        # Define trainer object\n",
        "        trainer = Trainer(\n",
        "            self.model,\n",
        "            args,\n",
        "            train_dataset=tokenized_datasets[\"train\"],\n",
        "            eval_dataset=tokenized_datasets[\"validation\"] if tokenized_datasets.get(\"validation\") is not None else None,\n",
        "            tokenizer=self.tokenizer,\n",
        "            data_collator = self.data_collator\n",
        "        )\n",
        "        print(\"Trainer device:\", trainer.args.device)\n",
        "\n",
        "        # Finetune the model\n",
        "        torch.cuda.empty_cache()\n",
        "        print('\\nModel training started ....')\n",
        "        trainer.train()\n",
        "\n",
        "        # Save best model\n",
        "        trainer.save_model()\n",
        "        return trainer\n",
        "\n",
        "    def get_labels(self, tokenized_dataset, batch_size = 4, sample_set = 'train'):\n",
        "        \"\"\"\n",
        "        Get the predictions from the trained model.\n",
        "        \"\"\"\n",
        "        def collate_fn(batch):\n",
        "            input_ids = [torch.tensor(example['input_ids']) for example in batch]\n",
        "            input_ids = pad_sequence(input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
        "            return input_ids\n",
        "\n",
        "        dataloader = DataLoader(tokenized_dataset[sample_set], batch_size=batch_size, collate_fn=collate_fn)\n",
        "        predicted_output = []\n",
        "        self.model.to(self.device)\n",
        "        print('Model loaded to: ', self.device)\n",
        "\n",
        "        for batch in tqdm(dataloader):\n",
        "            batch = batch.to(self.device)\n",
        "            output_ids = self.model.generate(batch)\n",
        "            output_texts = self.tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
        "            for output_text in output_texts:\n",
        "                predicted_output.append(output_text)\n",
        "        return predicted_output\n",
        "\n",
        "    def get_metrics(self, y_true, y_pred):\n",
        "        return precision_score(y_true, y_pred, average='macro'), recall_score(y_true, y_pred, average='macro'), \\\n",
        "            f1_score(y_true, y_pred, average='macro'), accuracy_score(y_true, y_pred)"
      ],
      "metadata": {
        "id": "5gKttC5d-qA3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kevinscaria/ate_tk-instruct-base-def-pos-neg-neut-combined"
      ],
      "metadata": {
        "id": "QRUbzPZN7Cey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t5_exp = T5Generator(model_checkpoint)\n",
        "bos_instruction_id = instruct_handler.ate[indomain]\n",
        "if ood_tr_data_path is not None or ood_te_data_path is not None:\n",
        "    bos_instruction_ood = instruct_handler.ate[outdomain]\n",
        "eos_instruction = instruct_handler.ate['eos_instruct']"
      ],
      "metadata": {
        "id": "ZjUh6Fz-BXmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece evaluate datasets"
      ],
      "metadata": {
        "id": "FzzfLayJCo6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/yangheng/deberta-v3-large-absa-v1.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xtoKKrxDGLW",
        "outputId": "b39aca7e-9310-4837-bda4-dbb841c951fb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deberta-v3-large-absa-v1.1'...\n",
            "remote: Enumerating objects: 30, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 30 (delta 5), reused 2 (delta 2), pack-reused 18 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (30/30), 8.42 KiB | 1.05 MiB/s, done.\n",
            "Filtering content: 100% (3/3), 3.24 GiB | 43.93 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from instructions import InstructionsHandler\n",
        "instruct_handler = InstructionsHandler()\n",
        "instruct_handler.load_instruction_set1()\n",
        "bos_instruction_id = instruct_handler.ate['bos_instruct1']\n",
        "bos_instruction_id\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "O_RNw2JfE-T6",
        "outputId": "50c7e9c2-af1e-44df-f09c-8e0c036b93f0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Definition: The output will be the aspects (both implicit and explicit) which have an associated opinion that are extracted from the input text. In cases where there are no aspects the output should be noaspectterm.\\n        Positive example 1-\\n        input: I charge it at night and skip taking the cord with me because of the good battery life.\\n        output: battery life\\n        Positive example 2-\\n        input: I even got my teenage son one, because of the features that it offers, like, iChat, Photobooth, garage band and more!.\\n        output: features, iChat, Photobooth, garage band\\n        Now complete the following example-\\n        input: '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_input=\"I recently purchased the new XYZ smartphone, and overall, I'm quite impressed. The camera quality is exceptional, capturing vibrant and clear photos even in low-light conditions. The battery life is also impressive; I can easily get through a full day of heavy use without needing to recharge. However, the screen brightness could be better—it's a bit difficult to see under direct sunlight. Additionally, while the design is sleek and modern, the weight of the phone feels a bit cumbersome after prolonged use. The customer service experience was positive, with prompt responses and helpful support.\""
      ],
      "metadata": {
        "id": "QiaKDZa3IRkh"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# from InstructABSA.utils import T5Generator\n",
        "# from InstructABSA.config import Config\n",
        "from instructions import InstructionsHandler\n",
        "\n",
        "model_checkpoint=\"kevinscaria/ate_tk-instruct-base-def-pos-neg-neut-combined\"\n",
        "\n",
        "instruct_handler = InstructionsHandler()\n",
        "instruct_handler.load_instruction_set1()\n",
        "\n",
        "# Load the T5 model for ATE task\n",
        "t5_exp = T5Generator(model_checkpoint)\n",
        "\n",
        "# Load ATE instructions\n",
        "bos_instruction_id = instruct_handler.ate['bos_instruct1']\n",
        "eos_instruction = instruct_handler.ate['eos_instruct']\n",
        "\n",
        "# Single input for inference\n",
        "#test_input = \"The camera quality of this phone is amazing.\"\n",
        "\n",
        "# Prepare the model input\n",
        "model_input = bos_instruction_id + test_input + eos_instruction\n",
        "\n",
        "# Tokenize input\n",
        "input_ids = t5_exp.tokenizer(model_input, return_tensors=\"pt\").input_ids\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZgHXKBFCV0H",
        "outputId": "8a6f19c7-9e22-4214-ef79-967de95edc2b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "<ipython-input-22-71b899bf3f3f>:18: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'\n",
            "  self.device = 'cuda' if torch.has_cuda else ('mps' if torch.has_mps else 'cpu')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform inference\n",
        "with torch.no_grad():\n",
        "    outputs = t5_exp.model.generate(input_ids, max_length=1024)\n",
        "\n",
        "# Decode and print the output\n",
        "predicted_text = t5_exp.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "word_list=predicted_text.split()\n",
        "print(f\"Model output: {predicted_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCof5EORILwg",
        "outputId": "503d369e-6006-48ed-afb1-80a74f6a794b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model output: camera quality, battery life, screen brightness, design, weight, phone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ky5wEjnOOE3",
        "outputId": "9168bba0-713b-4723-98af-af72d0ce3740"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([    0,  1861,   463,     6,  3322,   280,     6,  1641, 24073,     6,\n",
              "          408,     6,  1293,     6,   951,     1])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxnNFvphQ1qE",
        "outputId": "ee7b1cd3-c3a9-4fc5-a26f-26798c87a4ca"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['camera',\n",
              " 'quality,',\n",
              " 'battery',\n",
              " 'life,',\n",
              " 'screen',\n",
              " 'brightness,',\n",
              " 'design,',\n",
              " 'weight,',\n",
              " 'phone']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aspects=word_list"
      ],
      "metadata": {
        "id": "QYoqxHL-OkWo"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"i love camera\"\n",
        "#aspects = ['camera', 'phone']\n",
        "\n",
        "# Loop over aspects and classify\n",
        "for aspect in aspects:\n",
        "    sentiment, probabilities = classify_text(model, tokenizer, text, aspect)\n",
        "\n",
        "    # Output similar to pipeline\n",
        "    print(f\"Aspect: {aspect}, Sentiment: {sentiment}, Probabilities: {torch.argmax(probabilities, dim=-1)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9UVPt6PNwTG",
        "outputId": "d4e54402-af36-4edb-da3e-4aa672e8a856"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aspect: camera, Sentiment: positive, Probabilities: tensor([2])\n",
            "Aspect: quality,, Sentiment: positive, Probabilities: tensor([2])\n",
            "Aspect: battery, Sentiment: positive, Probabilities: tensor([2])\n",
            "Aspect: life,, Sentiment: positive, Probabilities: tensor([2])\n",
            "Aspect: screen, Sentiment: positive, Probabilities: tensor([2])\n",
            "Aspect: brightness,, Sentiment: positive, Probabilities: tensor([2])\n",
            "Aspect: design,, Sentiment: positive, Probabilities: tensor([2])\n",
            "Aspect: weight,, Sentiment: positive, Probabilities: tensor([2])\n",
            "Aspect: phone, Sentiment: positive, Probabilities: tensor([2])\n"
          ]
        }
      ]
    }
  ]
}